"""
Inventory Processing Module

Processes and filters Copart inventory data based on specified criteria.
"""

import logging
import re

import pandas as pd
import numpy as np
from typing import Optional, Dict, Any, List, Tuple

from config import AnalyzerConfig

logger = logging.getLogger(__name__)


class InventoryProcessor:
    """Processes Copart inventory data with filtering and validation"""

    def __init__(self,
                 dealer_patterns: Optional[Dict[str, Any]] = None,
                 top_makes: int = 10,
                 top_years: int = 10,
                 top_locations: int = 10,
                 top_damage_types: int = 8,
                 config: AnalyzerConfig = None):
        self.processed_inventory = None
        self.dealer_patterns = dealer_patterns or {}
        self.top_makes = top_makes
        self.top_years = top_years
        self.top_locations = top_locations
        self.top_damage_types = top_damage_types
        self.config = config or AnalyzerConfig()
        self.total_records = 0
        self.dynamic_filters = self._build_dynamic_filters()

    def _build_dynamic_filters(self) -> Dict[str, Any]:
        """Derive inventory filters from the dealer's own purchase patterns."""

        def _sorted_keys(preference_map: Dict[Any, float]) -> List[Any]:
            if not preference_map:
                return []
            sorted_items = sorted(preference_map.items(), key=lambda item: item[1], reverse=True)
            return [item[0] for item in sorted_items if item[1] > 0]

        make_prefs = self.dealer_patterns.get('make_preferences', {}) or {}
        model_prefs = self.dealer_patterns.get('model_preferences', {}) or {}
        year_prefs = self.dealer_patterns.get('year_preferences', {}) or {}
        location_prefs = self.dealer_patterns.get('location_preferences', {}) or {}
        damage_prefs = self.dealer_patterns.get('damage_tolerance', {}) or {}

        makes_full = [str(make).upper() for make in _sorted_keys(make_prefs)]
        years_full = [int(year) for year in _sorted_keys(year_prefs)]
        locations_full = [str(loc).upper() for loc in _sorted_keys(location_prefs)]
        location_states_full: List[str] = []
        for loc in locations_full:
            state = self._extract_state(loc)
            if state and state not in location_states_full:
                location_states_full.append(state)

        # Flatten model preferences to capture the dominant trims per make.
        aggregated_models: Dict[str, float] = {}
        for make_models in model_prefs.values():
            for model_name, freq in (make_models or {}).items():
                key = str(model_name).upper()
                aggregated_models[key] = max(aggregated_models.get(key, 0.0), freq)
        models_full = [model for model in _sorted_keys(aggregated_models)]

        damage_full = [str(dmg).upper() for dmg in _sorted_keys(damage_prefs)]

        filter_profile = {
            'makes': makes_full[: self.top_makes],
            'years': years_full[: self.top_years],
            'locations': locations_full[: self.top_locations],
            'models': models_full[: self.top_makes * 2],
            'damage_types': damage_full[: self.top_damage_types],
            'makes_full': makes_full,
            'years_full': years_full,
            'locations_full': locations_full,
            'location_states': location_states_full[: self.top_locations],
            'location_states_full': location_states_full,
            'models_full': models_full,
            'damage_types_full': damage_full,
        }

        logger.info(
            "Dynamic inventory filter profile built",
            extra={'filter_profile': {
                'makes': filter_profile['makes'],
                'years': filter_profile['years'],
                'locations': filter_profile['locations'],
                'models': filter_profile['models'],
                'damage_types': filter_profile['damage_types'],
            }}
        )

        return filter_profile
        
    def filter_inventory(self, 
                        inventory_file: str,
                        min_odometer: int = 80000,
                        max_odometer: int = 150000) -> pd.DataFrame:
        """
        Filter Copart inventory based on specified criteria
        
        Args:
            inventory_file: Path to Copart inventory CSV file
            min_odometer: Minimum odometer reading
            max_odometer: Maximum odometer reading
            
        Returns:
            Filtered DataFrame with eligible vehicles
        """
        logger.info(f"Processing inventory from {inventory_file}")
        
        # Load inventory data
        inventory_data = self._load_inventory_data(inventory_file)
        
        if inventory_data.empty:
            logger.error("No inventory data loaded")
            return pd.DataFrame()
            
        logger.info(f"Loaded {len(inventory_data)} total inventory records")
        
        # Clean and prepare data
        cleaned_data = self._clean_inventory_data(inventory_data)
        
        filtered_data, filter_settings = self._adaptive_filter_inventory(
            cleaned_data,
            min_odometer,
            max_odometer
        )
        
        # Validate and enhance data
        validated_data = self._validate_and_enhance(filtered_data)
        
        logger.info(f"Filtered inventory: {len(validated_data)} vehicles meet criteria")
        
        self.processed_inventory = validated_data
        self.dynamic_filters['active_filter_settings'] = filter_settings
        return validated_data
    
    def _load_inventory_data(self, inventory_file: str) -> pd.DataFrame:
        """Load Copart inventory data from CSV file"""
        try:
            logger.debug(f"Loading inventory data from {inventory_file}")
            
            # Use chunks for large files to manage memory
            chunk_size = 10000
            chunks = []
            
            # Read in chunks with error handling
            try:
                for chunk in pd.read_csv(inventory_file, chunksize=chunk_size, encoding='utf-8'):
                    chunks.append(chunk)
            except UnicodeDecodeError:
                logger.debug("UTF-8 failed, trying latin-1 encoding")
                for chunk in pd.read_csv(inventory_file, chunksize=chunk_size, encoding='latin-1'):
                    chunks.append(chunk)
            
            if chunks:
                data = pd.concat(chunks, ignore_index=True)
                self.total_records = len(data)
                logger.debug(f"Successfully loaded {self.total_records} inventory records")
                return data
            else:
                self.total_records = 0
                logger.error("No data chunks loaded")
                return pd.DataFrame()
                
        except Exception as e:
            logger.error(f"Error loading inventory data: {str(e)}")
            return pd.DataFrame()
    
    def _clean_inventory_data(self, data: pd.DataFrame) -> pd.DataFrame:
        """Clean and standardize inventory data"""
        logger.debug("Cleaning inventory data")
        
        # Create a copy to avoid modifying original
        cleaned_data = data.copy()
        
        # Standardize column names by removing quotes and spaces
        cleaned_data.columns = cleaned_data.columns.str.strip().str.replace('"', '')
        
        # Handle numeric columns
        numeric_columns = ['Year', 'Odometer', 'Est. Retail Value', 'Repair cost', 'High Bid =non-vix,Sealed=Vix']
        
        for col in numeric_columns:
            if col in cleaned_data.columns:
                # Convert to numeric, handling errors
                cleaned_data[col] = pd.to_numeric(cleaned_data[col], errors='coerce')
        
        # Clean text columns
        text_columns = ['Make', 'Model Group', 'Sale Status', 'Runs/Drives', 'Damage Description']
        
        for col in text_columns:
            if col in cleaned_data.columns:
                cleaned_data[col] = cleaned_data[col].astype(str).str.strip().str.upper()
        
        # Handle boolean-like columns
        if 'Runs/Drives' in cleaned_data.columns:
            # Map various "yes" values to standardized format
            cleaned_data['Runs/Drives'] = cleaned_data['Runs/Drives'].replace({
                'RUN & DRIVE VERIFIED': 'YES',
                'VEHICLE STARTS': 'YES', 
                'DEFAULT': 'NO',
                'NAN': 'NO'
            })
        
        logger.debug("Data cleaning complete")
        return cleaned_data
    
    def _adaptive_filter_inventory(self,
                                   cleaned_data: pd.DataFrame,
                                   base_min_odometer: int,
                                   base_max_odometer: int) -> Tuple[pd.DataFrame, Dict[str, Any]]:
        """Apply progressively relaxed filters until recall targets are met."""
        recall_cfg = self.config.recall
        filter_levels = self._generate_filter_levels()

        best_result = pd.DataFrame()
        best_settings: Dict[str, Any] = {}

        for level_index, level in enumerate(filter_levels):
            min_odometer, max_odometer = base_min_odometer, base_max_odometer
            for attempt in range(recall_cfg.max_relax_attempts):
                filtered = self._apply_filters(
                    cleaned_data,
                    min_odometer=min_odometer,
                    max_odometer=max_odometer,
                    filter_level=level
                )

                if filtered.size > 0 and (best_result.empty or len(filtered) > len(best_result)):
                    best_result = filtered
                    best_settings = {
                        'filter_level': level['name'],
                        'odometer_min': min_odometer,
                        'odometer_max': max_odometer,
                        'attempt': attempt + 1,
                    }

                if len(filtered) >= recall_cfg.min_results:
                    return filtered, best_settings

                # Expand odometer window for next attempt
                expanded_min, expanded_max = self._expand_odometer_bounds(min_odometer, max_odometer)
                if (expanded_min, expanded_max) == (min_odometer, max_odometer):
                    break  # Cannot expand further
                min_odometer, max_odometer = expanded_min, expanded_max

            # Proceed to next relaxation level if still under target

        return best_result, best_settings

    def _generate_filter_levels(self) -> List[Dict[str, Any]]:
        """Define progressive filter relaxation levels."""
        makes_full = self.dynamic_filters.get('makes_full', [])
        models_full = self.dynamic_filters.get('models_full', [])
        years_full = self.dynamic_filters.get('years_full', [])
        locations_full = self.dynamic_filters.get('locations_full', [])
        location_states_full = self.dynamic_filters.get('location_states_full', [])

        levels = [
            {
                'name': 'strict',
                'use_locations': True,
                'use_damage': True,
                'make_limit': min(self.top_makes, len(makes_full)) or None,
                'model_limit': min(self.top_makes * 2, len(models_full)) or None,
                'year_window': min(self.top_years, len(years_full)) or None,
                'damage_limit': self.top_damage_types,
                'location_limit': self.top_locations,
                'location_state_limit': self.top_locations,
            },
            {
                'name': 'balanced',
                'use_locations': True,
                'use_damage': True,
                'make_limit': min(len(makes_full), max(self.top_makes, 15)) or None,
                'model_limit': min(len(models_full), max(self.top_makes * 3, 25)) or None,
                'year_window': min(len(years_full), self.top_years + self.config.recall.year_expansion_step) or None,
                'damage_limit': None,
                'location_limit': min(len(locations_full), max(self.top_locations, 15)) or None,
                'location_state_limit': min(len(location_states_full), max(self.top_locations, 15)) or None,
            },
            {
                'name': 'broad',
                'use_locations': True,
                'use_damage': True,
                'make_limit': None,
                'model_limit': None,
                'year_window': min(len(years_full), self.top_years + self.config.recall.year_expansion_step * 2) or None,
                'damage_limit': None,
                'location_limit': None,
                'location_state_limit': None,
            },
            {
                'name': 'open',
                'use_locations': True,
                'use_damage': False,
                'make_limit': None,
                'model_limit': None,
                'year_window': None,
                'damage_limit': None,
                'location_limit': None,
                'location_state_limit': None,
            },
        ]

        max_levels = max(1, self.config.recall.max_relax_attempts)
        return levels[:max_levels]

    def _expand_odometer_bounds(self, min_odometer: int, max_odometer: int) -> Tuple[int, int]:
        """Widen the odometer range within configured floors/ceilings."""
        cfg = self.config.recall
        new_min = max(cfg.min_odometer_floor, min_odometer - cfg.odometer_step)
        new_max = min(cfg.max_odometer_ceiling, max_odometer + cfg.odometer_step)
        return new_min, new_max

    def _select_preferences(self, key: str, limit: Optional[int]) -> List[Any]:
        """Return a slice of preferred values respecting optional limits."""
        full_key = f"{key}_full"
        full_list = self.dynamic_filters.get(full_key, self.dynamic_filters.get(key, [])) or []
        if limit is None or limit <= 0:
            return full_list
        return full_list[:limit]

    @staticmethod
    def _extract_state(location: str) -> str:
        """Extract the state code from a location descriptor."""
        if not location:
            return ''
        normalized = str(location).upper().strip()
        if ' - ' in normalized:
            return normalized.split(' - ')[0].strip()
        parts = normalized.split()
        return parts[0].strip() if parts else ''

    def _apply_filters(self,
                      data: pd.DataFrame,
                      min_odometer: int,
                      max_odometer: int,
                      filter_level: Dict[str, Any]) -> pd.DataFrame:
        """Apply filtering criteria to inventory data"""
        logger.debug("Applying inventory filters")

        initial_count = len(data)
        filtered_data = data.copy()
        
        # Filter 1: Sale Status = "PURE SALE"
        if 'Sale Status' in filtered_data.columns:
            filtered_data = filtered_data[filtered_data['Sale Status'] == 'PURE SALE']
            logger.debug(f"After Pure Sale filter: {len(filtered_data)} vehicles (removed {initial_count - len(filtered_data)})")
        
        # Filter 2: Runs/Drives = "YES"
        if 'Runs/Drives' in filtered_data.columns:
            before_count = len(filtered_data)
            filtered_data = filtered_data[filtered_data['Runs/Drives'] == 'YES']
            logger.debug(f"After Runs/Drives filter: {len(filtered_data)} vehicles (removed {before_count - len(filtered_data)})")
        
        # Filter 3: Odometer range
        if 'Odometer' in filtered_data.columns:
            before_count = len(filtered_data)
            filtered_data = filtered_data[
                (filtered_data['Odometer'] >= min_odometer) & 
                (filtered_data['Odometer'] <= max_odometer) &
                (filtered_data['Odometer'].notna())
            ]
            logger.debug(f"After odometer filter ({min_odometer:,}-{max_odometer:,}): {len(filtered_data)} vehicles (removed {before_count - len(filtered_data)})")
        
        # Filter 4: Remove vehicles with missing critical data
        critical_columns = ['Year', 'Make', 'Model Group']
        before_count = len(filtered_data)
        
        for col in critical_columns:
            if col in filtered_data.columns:
                filtered_data = filtered_data[filtered_data[col].notna()]
        
        logger.debug(f"After missing data filter: {len(filtered_data)} vehicles (removed {before_count - len(filtered_data)})")
        
        # Filter 5: Reasonable year range
        if 'Year' in filtered_data.columns:
            before_count = len(filtered_data)
            current_year = 2025  # Based on provided date
            filtered_data = filtered_data[
                (filtered_data['Year'] >= 2000) & 
                (filtered_data['Year'] <= current_year)
            ]
            logger.debug(f"After year range filter (2000-{current_year}): {len(filtered_data)} vehicles (removed {before_count - len(filtered_data)})")
        
        # Filter 6: Align with dealer-preferred damage types
        preferred_damage = self._select_preferences('damage_types', filter_level.get('damage_limit'))
        if filter_level.get('use_damage', True) and preferred_damage and 'Damage Description' in filtered_data.columns:
            before_count = len(filtered_data)
            damage_tokens = '|'.join(re.escape(d) for d in preferred_damage)
            pattern = rf"({damage_tokens})"
            damage_mask = filtered_data['Damage Description'].str.contains(pattern, case=False, na=False)
            filtered_data = filtered_data[damage_mask]
            logger.debug(
                "After dynamic damage filter: %s vehicles (removed %s)",
                len(filtered_data),
                before_count - len(filtered_data)
            )

        # Filter 7: Dealer-favorite yards or locations
        preferred_locations = self._select_preferences('locations', filter_level.get('location_limit'))
        preferred_location_states = self._select_preferences('location_states', filter_level.get('location_state_limit'))
        if filter_level.get('use_locations', True) and (preferred_locations or preferred_location_states):
            uppercase_locations = [loc.upper() for loc in preferred_locations]
            before_count = len(filtered_data)

            yard_mask = None
            if 'Yard name' in filtered_data.columns:
                yard_mask = filtered_data['Yard name'].str.upper().isin(uppercase_locations)

            location_mask = None
            if 'Location' in filtered_data.columns:
                location_mask = filtered_data['Location'].str.upper().isin(uppercase_locations)

            combined_mask = None
            if yard_mask is not None:
                combined_mask = yard_mask
            if location_mask is not None:
                combined_mask = location_mask if combined_mask is None else (combined_mask | location_mask)

            uppercase_states = [state.upper() for state in preferred_location_states]
            if uppercase_states:
                state_masks = []
                if 'Location state' in filtered_data.columns:
                    state_masks.append(filtered_data['Location state'].astype(str).str.upper().isin(uppercase_states))
                if 'Sale Title State' in filtered_data.columns:
                    state_masks.append(filtered_data['Sale Title State'].astype(str).str.upper().isin(uppercase_states))
                if 'Location' in filtered_data.columns:
                    location_states = filtered_data['Location'].astype(str).apply(lambda x: self._extract_state(x).upper())
                    state_masks.append(location_states.isin(uppercase_states))
                if 'Yard name' in filtered_data.columns:
                    yard_states = filtered_data['Yard name'].astype(str).apply(lambda x: self._extract_state(x).upper())
                    state_masks.append(yard_states.isin(uppercase_states))

                if state_masks:
                    state_mask_combined = state_masks[0]
                    for mask in state_masks[1:]:
                        state_mask_combined = state_mask_combined | mask
                    combined_mask = state_mask_combined if combined_mask is None else (combined_mask | state_mask_combined)

            if combined_mask is not None:
                filtered_data = filtered_data[combined_mask]
                logger.debug(
                    "After dynamic location filter: %s vehicles (removed %s)",
                    len(filtered_data),
                    before_count - len(filtered_data)
                )

        # Filter 8: Dealer-preferred makes and models
        preferred_makes = self._select_preferences('makes', filter_level.get('make_limit'))
        if preferred_makes and 'Make' in filtered_data.columns:
            before_count = len(filtered_data)
            make_mask = filtered_data['Make'].str.upper().isin(preferred_makes)
            filtered_data = filtered_data[make_mask]
            logger.debug(
                "After dynamic make filter: %s vehicles (removed %s)",
                len(filtered_data),
                before_count - len(filtered_data)
            )

        preferred_models = self._select_preferences('models', filter_level.get('model_limit'))
        if preferred_models and 'Model Group' in filtered_data.columns:
            before_count = len(filtered_data)
            model_tokens = '|'.join(re.escape(m) for m in preferred_models)
            model_mask = filtered_data['Model Group'].str.contains(model_tokens, case=False, na=False)
            filtered_data = filtered_data[model_mask]
            logger.debug(
                "After dynamic model filter: %s vehicles (removed %s)",
                len(filtered_data),
                before_count - len(filtered_data)
            )

        # Filter 9: Dealer-preferred year band
        preferred_years = self._select_preferences('years', filter_level.get('year_window'))
        if preferred_years and 'Year' in filtered_data.columns:
            before_count = len(filtered_data)
            year_mask = filtered_data['Year'].isin(preferred_years)
            filtered_data = filtered_data[year_mask]
            logger.debug(
                "After dynamic year filter: %s vehicles (removed %s)",
                len(filtered_data),
                before_count - len(filtered_data)
            )

        # Filter 10: Remove vehicles with no sale date (exclude 0's)
        if 'Sale Date M/D/CY' in filtered_data.columns:
            before_count = len(filtered_data)
            # Filter out rows where Sale Date is 0 or NaN
            date_filter = (filtered_data['Sale Date M/D/CY'] != 0) & (filtered_data['Sale Date M/D/CY'].notna())
            filtered_data = filtered_data[date_filter]
            logger.debug(f"After sale date filter (excluding 0's): {len(filtered_data)} vehicles (removed {before_count - len(filtered_data)})")
        
        logger.info(f"Total filtering: {initial_count} â†’ {len(filtered_data)} vehicles ({(len(filtered_data)/initial_count)*100:.1f}% retained)")
        
        return filtered_data
    
    def _validate_and_enhance(self, data: pd.DataFrame) -> pd.DataFrame:
        """Validate data quality and add enhancement columns"""
        logger.debug("Validating and enhancing data")
        
        enhanced_data = data.copy()
        
        # Add vehicle age
        if 'Year' in enhanced_data.columns:
            current_year = 2025
            enhanced_data['Vehicle_Age'] = current_year - enhanced_data['Year']
        
        # Add price categories
        high_bid_col = None
        for col in ['High Bid', 'High Bid =non-vix,Sealed=Vix']:
            if col in enhanced_data.columns:
                high_bid_col = col
                break
        
        if high_bid_col:
            enhanced_data['Price_Category'] = enhanced_data[high_bid_col].apply(self._categorize_price)
        
        # Add odometer categories
        if 'Odometer' in enhanced_data.columns:
            enhanced_data['Mileage_Category'] = enhanced_data['Odometer'].apply(self._categorize_mileage)
        
        # Create composite keys for matching
        if all(col in enhanced_data.columns for col in ['Make', 'Model Group']):
            enhanced_data['Make_Model'] = enhanced_data['Make'] + '_' + enhanced_data['Model Group']
        
        # Add damage severity classification
        if 'Damage Description' in enhanced_data.columns:
            enhanced_data['Damage_Severity'] = enhanced_data['Damage Description'].apply(self._classify_damage_severity)
        
        # Generate Copart direct links
        if 'Lot number' in enhanced_data.columns:
            enhanced_data['copart_link'] = enhanced_data.apply(self._generate_copart_link, axis=1)
        
        # Ensure required columns exist with defaults
        required_columns = ['score', 'score_breakdown']
        for col in required_columns:
            if col not in enhanced_data.columns:
                enhanced_data[col] = 0.0 if col == 'score' else ''
        
        logger.debug(f"Data validation complete: {len(enhanced_data)} vehicles validated")
        return enhanced_data
    
    def _categorize_price(self, price: Optional[float]) -> str:
        """Categorize vehicle price into ranges"""
        if pd.isna(price) or price <= 0:
            return 'UNKNOWN'
        elif price < 2000:
            return 'UNDER_2K'
        elif price < 5000:
            return 'BUDGET'
        elif price < 10000:
            return 'MID_RANGE'
        elif price < 20000:
            return 'HIGH_VALUE'
        else:
            return 'PREMIUM'
    
    def _categorize_mileage(self, odometer: Optional[float]) -> str:
        """Categorize vehicle mileage"""
        if pd.isna(odometer):
            return 'UNKNOWN'
        elif odometer < 50000:
            return 'LOW'
        elif odometer < 100000:
            return 'MODERATE'
        elif odometer < 150000:
            return 'HIGH'
        else:
            return 'VERY_HIGH'
    
    def _classify_damage_severity(self, damage: Optional[str]) -> str:
        """Classify damage severity based on description"""
        if pd.isna(damage) or damage == 'NAN':
            return 'UNKNOWN'
        
        damage = str(damage).upper()
        
        # Severe damage indicators
        severe_keywords = ['WATER/FLOOD', 'FIRE', 'BIOHAZARD', 'STRIPPED', 'ALL OVER']
        if any(keyword in damage for keyword in severe_keywords):
            return 'SEVERE'
        
        # Moderate damage indicators  
        moderate_keywords = ['FRONT END', 'REAR END', 'SIDE', 'VANDALISM']
        if any(keyword in damage for keyword in moderate_keywords):
            return 'MODERATE'
        
        # Minor damage indicators
        minor_keywords = ['MINOR DENT', 'SCRATCHES', 'NORMAL WEAR', 'MECHANICAL']
        if any(keyword in damage for keyword in minor_keywords):
            return 'MINOR'
        
        return 'MODERATE'  # Default for unclassified damage
    
    def _generate_copart_link(self, row: pd.Series) -> str:
        """Generate direct Copart link for a vehicle using lot number and vehicle details"""
        try:
            lot_number = row.get('Lot number', '')
            if pd.isna(lot_number) or lot_number == '':
                return ''
            
            # Convert lot number to string and remove any decimal points
            lot_number = str(int(float(lot_number)))
            
            # Get vehicle details for URL construction
            year = row.get('Year', '')
            make = row.get('Make', '').lower().replace(' ', '-') if pd.notna(row.get('Make')) else ''
            model = row.get('Model Group', '').lower().replace(' ', '-') if pd.notna(row.get('Model Group')) else ''
            
            # Get location for URL
            yard_name = row.get('Yard name', '')
            if pd.notna(yard_name):
                # Convert "VA - HAMPTON" to "va-hampton"
                location = yard_name.lower().replace(' - ', '-').replace(' ', '-')
            else:
                location = ''
            
            # Determine vehicle type (salvage is most common)
            vehicle_type = 'salvage'  # Default, could be enhanced based on title type
            
            # Construct the full descriptive URL
            if all([year, make, model, location]):
                full_url = f"https://www.copart.com/lot/{lot_number}/{vehicle_type}-{year}-{make}-{model}-{location}"
            else:
                # Fallback to simple URL if missing details
                full_url = f"https://www.copart.com/lot/{lot_number}"
            
            return full_url
            
        except Exception as e:
            # If anything goes wrong, return simple lot URL
            lot_number = row.get('Lot number', '')
            if pd.notna(lot_number):
                try:
                    lot_number = str(int(float(lot_number)))
                    return f"https://www.copart.com/lot/{lot_number}"
                except:
                    return ''
            return ''
